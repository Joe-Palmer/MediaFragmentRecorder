<!DOCTYPE html>
<html>
<!-- recordMediaFragments.js demo https://github.com/guest271314/recordMediaFragments/tree/master/demos 2017 guest271314 -->
<head>
  <!-- https://github.com/guest271314/recordMediaFragments/ts-ebml -->
  <script type="text/javascript" src="ts-ebml-min.js"></script>
</head>

<body>
  <video preload="auto" width="320" height="280"></video>
  <script>
    const tsebml = require("ts-ebml");

    const video = document.querySelector("video");

    const videoStream = document.createElement("video");

    // `MediaSource`
    const mediaSource = new MediaSource();
    // for firefox 
    // see https://bugzilla.mozilla.org/show_bug.cgi?id=1259788
    const hasCaptureStream = HTMLMediaElement.prototype.hasOwnProperty("captureStream");

    videoStream.width = video.width;

    videoStream.height = video.height;

    const mimeCodec = "video/webm;codecs=vp8,opus";
    // for firefox
    let blob, canvas, ctx, currentBlobURL, currentFragmentURL,
      drawVideo, hash, raf = 0,
      request;

    if (!hasCaptureStream) {
      // no audio output
      // TODO fix audio output
      videoStream.crossOrigin = "anonymous";
      canvas = document.createElement("canvas");

      canvas.setAttribute("width", video.width);
      canvas.setAttribute("height", video.height);

      document.body.appendChild(canvas);

      ctx = canvas.getContext("2d");

      drawVideo = (ctx, currentVideo, stream, timeStamp) => {
        ctx.drawImage(currentVideo, 0, 0);
        if (stream.active) {
          raf = window.requestAnimationFrame(drawVideo.bind(null, ctx, currentVideo, stream));
        } else {
          window.cancelAnimationFrame(raf);
        }
      }
    }
    // https://gist.github.com/jsturgis/3b19447b304616f18657
    // https://www.w3.org/2010/05/video/mediaevents.html
    const multipleUrls = [
      "https://media.w3.org/2010/05/sintel/trailer.mp4#t=0,5",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=55,60",
      "https://raw.githubusercontent.com/w3c/web-platform-tests/master/media-source/mp4/test.mp4#t=0,5",
      "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerBlazes.mp4#t=0,5",
      "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerJoyrides.mp4#t=0,5",
      "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerMeltdowns.mp4#t=0,6",

      "https://media.w3.org/2010/05/video/movie_300.mp4#t=30,36"
    ];

    const singleUrl = [
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=0,1",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=1,2",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=2,3",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=3,4",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=4,5",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=5,6",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=6,7",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=7,8",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=8,9",
      "https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4#t=9,10"
    ];
    // firefox bug with more than five URLs
    // last loop does not complete
    const geckoUrl = [
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=10,11",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=11,12",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=12,13",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=13,14",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=14,15",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=15,16",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=16,17",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=17,18",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=18,19",
      "https://mirrors.creativecommons.org/movingimages/webm/ScienceCommonsJesseDylan_240p.webm#t=19,20"
    ];

    const mediaFragmentRecorder = async(urls) => {
      // `ts-ebml`
      const tsebmlTools = async() => ({
        decoder: new tsebml.Decoder(),
        encoder: new tsebml.Encoder(),
        reader: new tsebml.Reader(),
        tools: tsebml.tools
      });
      // create `ArrayBuffer` from `Blob`
      const readAsArrayBuffer = (blob) => {
          return new Promise((resolve, reject) => {
            const fr = new FileReader();
            fr.readAsArrayBuffer(blob);
            fr.onloadend = () => {
              resolve(fr.result);
            };
            fr.onerror = (ev) => {
              reject(ev.error);
            };
          });
        }
        // `urls`: string or array of URLs
        // record each media fragment
      const recordMediaFragments = async(video, mimeCodec, decoder, encoder, reader, tools, ...urls) => {
          urls = [].concat(...urls);
          const media = [];
          for (let url of urls) {
            await new Promise(async(resolve) => {

              videoStream.width = video.width;
              videoStream.height = video.height;

              // for firefox
              let audioContext, audioMediaStream, audioStream, canvasStream, gainNode, mediaStream, recorder,
                sourceNode;

              videoStream.onprogress = e => {
                console.log("loading " + url)
              }

              videoStream.oncanplay = async(e) => {
                // for firefox 
                if (!hasCaptureStream) {
                  ctx.clearRect(0, 0, canvas.width, canvas.height)
                };

                videoStream.oncanplay = null;
                videoStream.play();

                mediaStream = await new Promise(resolveMediaStream => {
                  if (hasCaptureStream) {
                    resolveMediaStream(videoStream.captureStream());
                  }
                  // for firefox
                  else {
                    audioContext = new AudioContext();

                    audioMediaStream = audioContext.createMediaStreamDestination();
                    sourceNode = audioContext.createMediaElementSource(videoStream);
                    gainNode = audioContext.createGain();
                    gainNode.gain.value = 0;
                    gainNode.connect(audioContext.destination)
                    sourceNode.connect(audioContext.destination);
                    sourceNode.connect(audioMediaStream);
                    audioStream = audioMediaStream.stream;
                    drawVideo(ctx, videoStream, audioStream);
                    canvasStream = canvas.captureStream(60);
                    audioStream.addTrack(canvasStream.getVideoTracks()[0]);

                    resolveMediaStream(audioStream);
                  }

                });
                // record `MediaStream`
                recorder = new MediaRecorder(mediaStream, {
                  mimeType: mimeCodec
                });

                recorder.ondataavailable = async(e) => {
                  // stop `MediaStreamTrack`s
                  for (let track of mediaStream.getTracks()) {
                    track.stop();
                  }
                  // set metadata of recorded media fragment `Blob`
                  const mediaBlob = await setMediaMetadata(e.data);
                  // create `ArrayBuffer` of `Blob` of recorded media fragment
                  const mediaBuffer = await readAsArrayBuffer(mediaBlob);
                  const mediaDuration = videoStream.played.end(0) - videoStream.played.start(0);
                  const mediaFragmentId = currentFragmentURL || new URL(url);
                  const mediaFileName = mediaFragmentId.pathname.split("/").pop() + mediaFragmentId.hash;
                  const mediaFragmentType = "singleMediaFragment";
                  media.push({
                    mediaBlob, mediaBuffer, mediaDuration, mediaFragmentType, mediaFileName
                  });
                  resolve();
                  if (currentBlobURL) {
                    URL.revokeObjectURL(currentBlobURL);
                  }
                  if (audioContext) {
                    audioContext.close()
                  }
                }
                recorder.start();
              }
              videoStream.onpause = e => {
                  videoStream.onpause = null;
                  recorder.stop();
                  // stop `MediaStreamTrack`s
                  for (let ms of[audioStream, canvasStream, mediaStream]) {
                    if (ms) {
                      for (let track of ms.getTracks()) {
                        track.stop();
                      }
                    }
                  }
                  // for firefox, close `AudioContext`
                  // try to get audio output
                }
                // attempt to work around no audio output
                // for cross origin URL
                // does not result in audio output
                /*
                if (!hasCaptureStream) {
                  currentFragmentURL = new URL(url);
                  console.log(currentFragmentURL);
                  request = new Request(currentFragmentURL.href);
                  blob = await fetch(request).then(response => response.blob());
                  console.log(blob);
                  currentBlobURL = URL.createObjectURL(blob);
                  url = `${currentBlobURL}${currentFragmentURL.hash}`
                }
                */
              videoStream.src = url;
            }).catch(err => err)
          }
          return media
        }
        // set metadata of media `Blob`
        // see https://github.com/legokichi/ts-ebml/issues/14#issuecomment-325200151
      const setMediaMetadata = async(blob) =>
        tsebmlTools()
        .then(async({
          decoder, encoder, tools, reader
        }) => {

          let webM = new Blob([], {
            type: "video/webm"
          });

          webM = new Blob([webM, blob], {
            type: blob.type
          });

          const buf = await readAsArrayBuffer(blob);
          const elms = decoder.decode(buf);
          elms.forEach((elm) => {
            reader.read(elm);
          });

          reader.stop();

          const refinedMetadataBuf = tools.makeMetadataSeekable(reader.metadatas, reader.duration, reader.cues);

          const webMBuf = await readAsArrayBuffer(webM);

          const body = webMBuf.slice(reader.metadataSize);
          const refinedWebM = new Blob([refinedMetadataBuf, body], {
            type: webM.type
          });
          // close Blobs
          if (webM.close && blob.close) {
            webM.close();
            blob.close();
          }

          return refinedWebM;
        })
        .catch(err => console.error(err));


      let mediaTools = await tsebmlTools();

      const {
        decoder, encoder, reader, tools
      } = mediaTools;

      const mediaFragments = await recordMediaFragments(video, mimeCodec, decoder, encoder, reader, tools, urls);

      const recordedMedia = await new Promise((resolveAllMedia, rejectAllMedia) => {
        console.log(decoder, encoder, tools, reader, mediaFragments);

        let audioContext, audioMediaStream, audioStream, canvasStream,
          gainNode, fragments, mediaStream, recorder, sourceNode;

        mediaSource.onsourceended = e => {
            video.ontimeupdate = e => {

              console.log(video.currentTime, mediaSource.duration);
              if (video.currentTime === mediaSource.duration) {
                video.ontimeupdate = null;
                recorder.stop();
                console.log(e, recorder);

                // stop `MediaStreamTrack`s
                for (let ms of[audioStream, canvasStream, mediaStream]) {
                  if (ms) {
                    for (let track of ms.getTracks()) {
                      track.stop();
                    }
                  }
                }
                // for firefox 
                if (audioContext) {
                  audioContext.close()
                };
              }
            }
          }
          // record `MediaSource` playback of recorded media fragments
        video.onplaying = async(e) => {
          console.log(e);
          video.onplaying = null;
          mediaStream = await new Promise(resolveMediaStream => {
            if (HTMLMediaElement.prototype.hasOwnProperty("captureStream")) {
              resolveMediaStream(video.captureStream());
            }
            // for firefox
            else {
              audioContext = new AudioContext();
              audioMediaStream = audioContext.createMediaStreamDestination();
              sourceNode = audioContext.createMediaElementSource(videoStream);
              gainNode = audioContext.createGain();
              gainNode.gain.value = 1;
              gainNode.connect(audioContext.destination)
              sourceNode.connect(audioContext.destination);
              sourceNode.connect(audioMediaStream);
              audioStream = audioMediaStream.stream;
              drawVideo(ctx, video, audioStream);
              canvasStream = canvas.captureStream(60);
              audioStream.addTrack(canvasStream.getVideoTracks()[0]);
              resolveMediaStream(audioStream);
            }

          });
          recorder = new MediaRecorder(mediaStream, {
            mimeType: mimeCodec
          });
          console.log(recorder);

          recorder.ondataavailable = async(e) => {

            // video.pause();
            const mediaFragmentsRecording = {};

            mediaFragmentsRecording.mediaBlob = await setMediaMetadata(e.data);
            mediaFragmentsRecording.mediaBuffer = await readAsArrayBuffer(mediaFragmentsRecording.mediaBlob);
            mediaFragmentsRecording.mediaFileName = urls.map(url => {
              const id = new URL(url);
              return id.pathname.split("/").pop() + id.hash
            }).join("-");
            mediaFragmentsRecording.mediaFragmentType = "multipleMediaFragments";
            // `<video>` to play concatened media fragments
            // recorded from playback of `MediaSource`
            fragments = document.createElement("video");
            fragments.id = "fragments";
            fragments.width = video.width;
            fragments.height = video.height;
            fragments.controls = true;
            fragments.onloadedmetadata = () => {

              console.log(fragments.duration);

            }
            document.body.appendChild(fragments);
            resolveAllMedia([
              ...mediaFragments, mediaFragmentsRecording
            ]);
          }

          recorder.start();
        }



        video.oncanplay = (e) => {
          console.log(e);
        }



        video.src = URL.createObjectURL(mediaSource);

        mediaSource.addEventListener("sourceopen", sourceOpen);

        async function sourceOpen(e) {


          if (MediaSource.isTypeSupported(mimeCodec)) {
            const sourceBuffer = mediaSource.addSourceBuffer(mimeCodec);
            sourceBuffer.mode = "sequence";
            for (let {
                mediaBuffer, mediaDuration
              }
              of mediaFragments) {
              // for firefox
              if (!hasCaptureStream) {
                // ctx.clearRect(0, 0, canvas.width, canvas.height)
              };

              await new Promise(resolveUpdatedMediaSource => {

                sourceBuffer.onupdateend = e => {
                  sourceBuffer.onupdateend = null;
                  console.log(mediaDuration, mediaSource.duration, video.paused, video.ended, video.currentTime, e, "media source playing", video.readyState);

                  video.play().then(resolveUpdatedMediaSource)
                }
                sourceBuffer.appendBuffer(mediaBuffer);
              })
            }
            video.onwaiting = e => {
              video.onwaiting = null;
              console.log(e);
              mediaSource.endOfStream()
            }

            video.onended = (e) => {
              video.onended = null;
              console.log(e, video.currentTime,
                mediaSource.duration);
            }

          } else {
            console.warn(mimeCodec + " not supported");
          }
        };

      })

      return recordedMedia
    };

    mediaFragmentRecorder(geckoURL)
      .then(recordedMediaFragments => {
        // do stuff with recorded media fragments
        console.log(recordedMediaFragments);
        const select = document.createElement("select");
        for (let {
            mediaFileName, mediaBlob, mediaFragmentType
          }
          of Object.values(recordedMediaFragments)) {
          const option = new Option(mediaFileName, URL.createObjectURL(mediaBlob));
          select.appendChild(option);
        }
        select.onchange = () => {
          document.getElementById("fragments").src = select.value;
        }
        video.parentNode.insertBefore(select, video);
        video.controls = true;
      })
      .catch(err => console.error(err));
  </script>
</body>

</html>
